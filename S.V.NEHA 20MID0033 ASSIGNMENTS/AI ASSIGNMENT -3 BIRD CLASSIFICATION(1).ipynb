{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d06513b2",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d850c091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccabf26",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2a9dab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale = (1./255),horizontal_flip=True,shear_range=0.2,zoom_range=0.2)\n",
    "test_gen = ImageDataGenerator(rescale = (1./255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fc81bfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150 images belonging to 16 classes.\n",
      "Found 157 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "train=train_gen.flow_from_directory('C:/Users/svneh/Downloads/archive (6)/train_data/train_data',\n",
    "                                    target_size=(120,120),\n",
    "                                    class_mode='categorical',\n",
    "                                    batch_size=8)\n",
    "test=test_gen.flow_from_directory('C:/Users/svneh/Downloads/archive (6)/test_data/test_data',\n",
    "                                  target_size=(120,120),\n",
    "                                    class_mode='categorical',\n",
    "                                    batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8b6642",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0ac695c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Convolution2D(20,(3,3),activation = 'relu',input_shape=(120,120,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(45,activation = 'relu'),\n",
    "    Dense(16,activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7c1d3b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 118, 118, 20)      560       \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 59, 59, 20)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 69620)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 45)                3132945   \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 16)                736       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,134,241\n",
      "Trainable params: 3,134,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "301b8603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blasti': 0,\n",
       " 'bonegl': 1,\n",
       " 'brhkyt': 2,\n",
       " 'cbrtsh': 3,\n",
       " 'cmnmyn': 4,\n",
       " 'gretit': 5,\n",
       " 'hilpig': 6,\n",
       " 'himbul': 7,\n",
       " 'himgri': 8,\n",
       " 'hsparo': 9,\n",
       " 'indvul': 10,\n",
       " 'jglowl': 11,\n",
       " 'lbicrw': 12,\n",
       " 'mgprob': 13,\n",
       " 'rebimg': 14,\n",
       " 'wcrsrt': 15}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "46b8d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',metrics=['accuracy'],loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "80bdd13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19/19 [==============================] - 48s 3s/step - loss: 2.3758 - accuracy: 0.2067 - val_loss: 2.6395 - val_accuracy: 0.1656\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 57s 3s/step - loss: 2.3473 - accuracy: 0.2067 - val_loss: 2.6575 - val_accuracy: 0.1720\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 58s 3s/step - loss: 2.3584 - accuracy: 0.2133 - val_loss: 2.6559 - val_accuracy: 0.1720\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 59s 3s/step - loss: 2.3360 - accuracy: 0.2067 - val_loss: 2.6466 - val_accuracy: 0.1783\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 43s 2s/step - loss: 2.3339 - accuracy: 0.2067 - val_loss: 2.6147 - val_accuracy: 0.1783\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.3460 - accuracy: 0.2067 - val_loss: 2.7004 - val_accuracy: 0.1401\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.3837 - accuracy: 0.2067 - val_loss: 2.6379 - val_accuracy: 0.1847\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.3309 - accuracy: 0.1867 - val_loss: 2.6325 - val_accuracy: 0.1975\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.3547 - accuracy: 0.2000 - val_loss: 2.6463 - val_accuracy: 0.1975\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.3676 - accuracy: 0.2333 - val_loss: 2.7562 - val_accuracy: 0.0637\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 28s 1s/step - loss: 2.3967 - accuracy: 0.2133 - val_loss: 2.6740 - val_accuracy: 0.1911\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.3373 - accuracy: 0.2400 - val_loss: 2.6160 - val_accuracy: 0.1911\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.3151 - accuracy: 0.2333 - val_loss: 2.6191 - val_accuracy: 0.1975\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.3046 - accuracy: 0.2400 - val_loss: 2.6200 - val_accuracy: 0.1911\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.2957 - accuracy: 0.2267 - val_loss: 2.6326 - val_accuracy: 0.1975\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.2829 - accuracy: 0.2200 - val_loss: 2.6410 - val_accuracy: 0.1975\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.2857 - accuracy: 0.2333 - val_loss: 2.6578 - val_accuracy: 0.1847\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 28s 1s/step - loss: 2.3080 - accuracy: 0.2400 - val_loss: 2.6059 - val_accuracy: 0.1975\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.3215 - accuracy: 0.2400 - val_loss: 2.7480 - val_accuracy: 0.1592\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.2868 - accuracy: 0.2267 - val_loss: 2.6345 - val_accuracy: 0.1975\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(train,epochs =20,\n",
    "                     validation_data = test ,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8d7f161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('birds.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8811dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a44b4aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rebimg', 'wcrsrt', 'jglowl', 'ibicrw', 'mgprob', 'hsparo', 'indvul', 'himgri', 'himbul', 'gretit', 'hilpig', 'cbrtsh', 'cmnmyn', 'bonegl', 'brhkyt', 'blasti']\n"
     ]
    }
   ],
   "source": [
    "output = ['rebimg','wcrsrt','jglowl','ibicrw','mgprob','hsparo',\n",
    "         'indvul','himgri','himbul','gretit','hilpig','cbrtsh',\n",
    "         'cmnmyn','bonegl','brhkyt','blasti']\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "44950d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 112ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img1 = image.load_img(\"C:/Users/svneh/Downloads/jglowl.jpg\",target_size=(120,120))\n",
    "img1 = image.img_to_array(img1)\n",
    "img1 = np.expand_dims(img1,axis=0)\n",
    "pred = np.argmax(model.predict(img1))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "471ccd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img2 = image.load_img(\"C:/Users/svneh/Downloads/ibicrw.jpg\",target_size=(120,120))\n",
    "img2 = image.img_to_array(img2)\n",
    "img2 = np.expand_dims(img2,axis=0)\n",
    "pred = np.argmax(model.predict(img2))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "91dd2b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img3 = image.load_img(\"C:/Users/svneh/Downloads/rebimg.jpg\",target_size=(120,120))\n",
    "img3 = image.img_to_array(img3)\n",
    "img3 = np.expand_dims(img3,axis=0)\n",
    "pred = np.argmax(model.predict(img3))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5cc964fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\svneh\\\\OneDrive\\\\Desktop\\\\py jup'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4ade6239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img4 = image.load_img(\"C:/Users/svneh/Downloads/hilpig.jpg\",target_size=(120,120))\n",
    "img4 = image.img_to_array(img4)\n",
    "img4 = np.expand_dims(img4,axis=0)\n",
    "pred = np.argmax(model.predict(img4))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a8849dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img5 = image.load_img(\"C:/Users/svneh/Downloads/himbul.jpg\",target_size=(120,120))\n",
    "img5 = image.img_to_array(img5)\n",
    "img5 = np.expand_dims(img5,axis=0)\n",
    "pred = np.argmax(model.predict(img5))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4bf04323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img6 = image.load_img(\"C:/Users/svneh/Downloads/hsparo.jpg\",target_size=(120,120))\n",
    "img6 = image.img_to_array(img6)\n",
    "img6 = np.expand_dims(img6,axis=0)\n",
    "pred = np.argmax(model.predict(img6))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2626a00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img7 = image.load_img(\"C:/Users/svneh/Downloads/indvul.png\",target_size=(120,120))\n",
    "img7 = image.img_to_array(img7)\n",
    "img7 = np.expand_dims(img7,axis=0)\n",
    "pred = np.argmax(model.predict(img7))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4850b300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img8 = image.load_img(\"C:/Users/svneh/Downloads/gretit.png\",target_size=(120,120))\n",
    "img8 = image.img_to_array(img8)\n",
    "img8 = np.expand_dims(img8,axis=0)\n",
    "pred = np.argmax(model.predict(img8))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d19181fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "4\n",
      "mgprob\n"
     ]
    }
   ],
   "source": [
    "img9 = image.load_img(\"C:/Users/svneh/Downloads/wcrsrt.png\",target_size=(120,120))\n",
    "img9 = image.img_to_array(img9)\n",
    "img9 = np.expand_dims(img9,axis=0)\n",
    "pred = np.argmax(model.predict(img9))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d3e837b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img10 = image.load_img(\"C:/Users/svneh/Downloads/mgprop.png\",target_size=(120,120))\n",
    "img10 = image.img_to_array(img10)\n",
    "img10 = np.expand_dims(img10,axis=0)\n",
    "pred = np.argmax(model.predict(img10))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b207c7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img11 = image.load_img(\"C:/Users/svneh/Downloads/cbrtsh.png\",target_size=(120,120))\n",
    "img11 = image.img_to_array(img11)\n",
    "img11 = np.expand_dims(img11,axis=0)\n",
    "pred = np.argmax(model.predict(img11))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0f235c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img12 = image.load_img(\"C:/Users/svneh/Downloads/cmnmym.png\",target_size=(120,120))\n",
    "img12 = image.img_to_array(img12)\n",
    "img12 = np.expand_dims(img12,axis=0)\n",
    "pred = np.argmax(model.predict(img12))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6bea0e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img13 = image.load_img(\"C:/Users/svneh/Downloads/bonegl.png\",target_size=(120,120))\n",
    "img13 = image.img_to_array(img13)\n",
    "img13 = np.expand_dims(img13,axis=0)\n",
    "pred = np.argmax(model.predict(img13))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "49f92597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img14 = image.load_img(\"C:/Users/svneh/Downloads/blasti.png\",target_size=(120,120))\n",
    "img14 = image.img_to_array(img14)\n",
    "img14 = np.expand_dims(img14,axis=0)\n",
    "pred = np.argmax(model.predict(img14))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d6942e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img15 = image.load_img(\"C:/Users/svneh/Downloads/brhkyt.png\",target_size=(120,120))\n",
    "img15 = image.img_to_array(img15)\n",
    "img15 = np.expand_dims(img15,axis=0)\n",
    "pred = np.argmax(model.predict(img15))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3a1c11dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hence we can see that the model is not predicting the birds properly hence we can try it with model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d394705b",
   "metadata": {},
   "source": [
    "# Model Tuning ( Adding Feature extraction layrrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "62d1f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Convolution2D(15,(3,3),activation = 'relu',input_shape=(120,120,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Convolution2D(30,(3,3),activation = 'relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Convolution2D(45,(3,3),activation = 'relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Convolution2D(60,(3,3),activation = 'relu',input_shape=(120,120,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Convolution2D(75,(3,3),activation = 'relu',input_shape=(120,120,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(62,activation = 'relu'),\n",
    "    Dense(32,activation = 'relu'),\n",
    "    Dense(16,activation = 'relu'),\n",
    "    Dense(16,activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "11f8166e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_17 (Conv2D)          (None, 118, 118, 15)      420       \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 59, 59, 15)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 57, 57, 30)        4080      \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 28, 28, 30)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 26, 26, 45)        12195     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 13, 13, 45)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 11, 11, 60)        24360     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 5, 5, 60)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 3, 3, 75)          40575     \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 1, 1, 75)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 75)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 62)                4712      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 32)                2016      \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,158\n",
      "Trainable params: 89,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3b9e7e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',metrics=['accuracy'],loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ccc66d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 30s 2s/step - loss: 2.7775 - accuracy: 0.0667 - val_loss: 2.7618 - val_accuracy: 0.1019\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 26s 1s/step - loss: 2.7586 - accuracy: 0.1333 - val_loss: 2.7459 - val_accuracy: 0.1274\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.7415 - accuracy: 0.1333 - val_loss: 2.7358 - val_accuracy: 0.1274\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 30s 2s/step - loss: 2.7080 - accuracy: 0.1133 - val_loss: 2.7433 - val_accuracy: 0.1210\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.7382 - accuracy: 0.0933 - val_loss: 2.7142 - val_accuracy: 0.1210\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.7203 - accuracy: 0.1000 - val_loss: 2.7053 - val_accuracy: 0.1210\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.6569 - accuracy: 0.1467 - val_loss: 2.7435 - val_accuracy: 0.1274\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.6798 - accuracy: 0.1267 - val_loss: 2.7217 - val_accuracy: 0.1529\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 28s 1s/step - loss: 2.6299 - accuracy: 0.1733 - val_loss: 2.7022 - val_accuracy: 0.1210\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.6289 - accuracy: 0.1533 - val_loss: 2.7127 - val_accuracy: 0.1274\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.6133 - accuracy: 0.1467 - val_loss: 2.7072 - val_accuracy: 0.1083\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.5985 - accuracy: 0.1133 - val_loss: 2.7118 - val_accuracy: 0.1274\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 28s 1s/step - loss: 2.5526 - accuracy: 0.1467 - val_loss: 2.7245 - val_accuracy: 0.0701\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.5490 - accuracy: 0.1733 - val_loss: 2.7029 - val_accuracy: 0.1210\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.5671 - accuracy: 0.1933 - val_loss: 2.7024 - val_accuracy: 0.1210\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.5911 - accuracy: 0.1933 - val_loss: 2.7003 - val_accuracy: 0.1274\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 29s 2s/step - loss: 2.5278 - accuracy: 0.2000 - val_loss: 2.6979 - val_accuracy: 0.1210\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.4749 - accuracy: 0.2000 - val_loss: 2.7054 - val_accuracy: 0.1210\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 27s 2s/step - loss: 2.4886 - accuracy: 0.2067 - val_loss: 2.6790 - val_accuracy: 0.1146\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.4661 - accuracy: 0.2067 - val_loss: 2.6627 - val_accuracy: 0.1083\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 28s 1s/step - loss: 2.4687 - accuracy: 0.1933 - val_loss: 2.6742 - val_accuracy: 0.1656\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.4557 - accuracy: 0.1800 - val_loss: 2.8396 - val_accuracy: 0.1210\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.4292 - accuracy: 0.1533 - val_loss: 2.6755 - val_accuracy: 0.1338\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.3272 - accuracy: 0.2133 - val_loss: 2.7259 - val_accuracy: 0.1720\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 31s 2s/step - loss: 2.2773 - accuracy: 0.2200 - val_loss: 2.7094 - val_accuracy: 0.1656\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 30s 2s/step - loss: 2.2039 - accuracy: 0.2533 - val_loss: 2.7034 - val_accuracy: 0.1656\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.1453 - accuracy: 0.2600 - val_loss: 2.7774 - val_accuracy: 0.1465\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 30s 2s/step - loss: 2.1559 - accuracy: 0.2733 - val_loss: 2.7124 - val_accuracy: 0.1720\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 31s 2s/step - loss: 2.0974 - accuracy: 0.2933 - val_loss: 2.8033 - val_accuracy: 0.1465\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 31s 2s/step - loss: 2.0359 - accuracy: 0.2400 - val_loss: 2.7384 - val_accuracy: 0.1274\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.9586 - accuracy: 0.2933 - val_loss: 2.9330 - val_accuracy: 0.2166\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 1.9898 - accuracy: 0.3267 - val_loss: 2.8359 - val_accuracy: 0.1019\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 1.9849 - accuracy: 0.2667 - val_loss: 2.9023 - val_accuracy: 0.1656\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 1.8850 - accuracy: 0.2867 - val_loss: 3.1135 - val_accuracy: 0.1592\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 28s 1s/step - loss: 1.9481 - accuracy: 0.3333 - val_loss: 2.8762 - val_accuracy: 0.1529\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 1.7834 - accuracy: 0.3533 - val_loss: 3.0608 - val_accuracy: 0.1975\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 1.8118 - accuracy: 0.4000 - val_loss: 3.2737 - val_accuracy: 0.1465\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 1.8708 - accuracy: 0.3000 - val_loss: 2.9573 - val_accuracy: 0.1847\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 1.7042 - accuracy: 0.4067 - val_loss: 3.3099 - val_accuracy: 0.1720\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 1.7063 - accuracy: 0.4067 - val_loss: 3.4032 - val_accuracy: 0.1338\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 1.7592 - accuracy: 0.4000 - val_loss: 3.3134 - val_accuracy: 0.2038\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 1.6813 - accuracy: 0.4200 - val_loss: 3.3371 - val_accuracy: 0.1529\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 28s 1s/step - loss: 1.5221 - accuracy: 0.4600 - val_loss: 3.5573 - val_accuracy: 0.1592\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 1.5011 - accuracy: 0.4733 - val_loss: 3.7309 - val_accuracy: 0.1783\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 1.4673 - accuracy: 0.4600 - val_loss: 3.5507 - val_accuracy: 0.1847\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.4187 - accuracy: 0.4533 - val_loss: 3.8640 - val_accuracy: 0.1592\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 28s 1s/step - loss: 1.4263 - accuracy: 0.4867 - val_loss: 3.9452 - val_accuracy: 0.1338\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 1.2814 - accuracy: 0.5133 - val_loss: 4.5782 - val_accuracy: 0.1911\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 1.3525 - accuracy: 0.5000 - val_loss: 4.0549 - val_accuracy: 0.1975\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 1.2944 - accuracy: 0.5067 - val_loss: 4.3617 - val_accuracy: 0.1529\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(train,epochs =50,\n",
    "                     validation_data = test ,\n",
    "                      batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b7a52f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 369ms/step\n",
      "4\n",
      "mgprob\n"
     ]
    }
   ],
   "source": [
    "img1 = image.load_img(\"C:/Users/svneh/Downloads/jglowl.jpg\",target_size=(120,120))\n",
    "img1 = image.img_to_array(img1)\n",
    "img1 = np.expand_dims(img1,axis=0)\n",
    "pred = np.argmax(model.predict(img1))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c988dd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "9\n",
      "gretit\n"
     ]
    }
   ],
   "source": [
    "img2 = image.load_img(\"C:/Users/svneh/Downloads/ibicrw.jpg\",target_size=(120,120))\n",
    "img2 = image.img_to_array(img2)\n",
    "img2 = np.expand_dims(img2,axis=0)\n",
    "pred = np.argmax(model.predict(img2))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d1ec096f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "4\n",
      "mgprob\n"
     ]
    }
   ],
   "source": [
    "img3 = image.load_img(\"C:/Users/svneh/Downloads/rebimg.jpg\",target_size=(120,120))\n",
    "img3 = image.img_to_array(img3)\n",
    "img3 = np.expand_dims(img3,axis=0)\n",
    "pred = np.argmax(model.predict(img3))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c6564cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img6 = image.load_img(\"C:/Users/svneh/Downloads/hsparo.jpg\",target_size=(120,120))\n",
    "img6 = image.img_to_array(img6)\n",
    "img6 = np.expand_dims(img6,axis=0)\n",
    "pred = np.argmax(model.predict(img6))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "26000849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img5 = image.load_img(\"C:/Users/svneh/Downloads/himbul.jpg\",target_size=(120,120))\n",
    "img5 = image.img_to_array(img5)\n",
    "img5 = np.expand_dims(img5,axis=0)\n",
    "pred = np.argmax(model.predict(img5))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1d7636e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img4 = image.load_img(\"C:/Users/svneh/Downloads/hilpig.jpg\",target_size=(120,120))\n",
    "img4 = image.img_to_array(img4)\n",
    "img4 = np.expand_dims(img4,axis=0)\n",
    "pred = np.argmax(model.predict(img4))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b2a4c982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "8\n",
      "himbul\n"
     ]
    }
   ],
   "source": [
    "img7 = image.load_img(\"C:/Users/svneh/Downloads/indvul.png\",target_size=(120,120))\n",
    "img7 = image.img_to_array(img7)\n",
    "img7 = np.expand_dims(img7,axis=0)\n",
    "pred = np.argmax(model.predict(img7))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "94cbef56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "9\n",
      "gretit\n"
     ]
    }
   ],
   "source": [
    "img8 = image.load_img(\"C:/Users/svneh/Downloads/gretit.png\",target_size=(120,120))\n",
    "img8 = image.img_to_array(img8)\n",
    "img8 = np.expand_dims(img8,axis=0)\n",
    "pred = np.argmax(model.predict(img8))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8e71898a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "4\n",
      "mgprob\n"
     ]
    }
   ],
   "source": [
    "img9 = image.load_img(\"C:/Users/svneh/Downloads/wcrsrt.png\",target_size=(120,120))\n",
    "img9 = image.img_to_array(img9)\n",
    "img9 = np.expand_dims(img9,axis=0)\n",
    "pred = np.argmax(model.predict(img9))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8aeb093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "9\n",
      "gretit\n"
     ]
    }
   ],
   "source": [
    "img10 = image.load_img(\"C:/Users/svneh/Downloads/mgprop.png\",target_size=(120,120))\n",
    "img10 = image.img_to_array(img10)\n",
    "img10 = np.expand_dims(img10,axis=0)\n",
    "pred = np.argmax(model.predict(img10))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f7d2fd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "9\n",
      "gretit\n"
     ]
    }
   ],
   "source": [
    "img11 = image.load_img(\"C:/Users/svneh/Downloads/cbrtsh.png\",target_size=(120,120))\n",
    "img11 = image.img_to_array(img11)\n",
    "img11 = np.expand_dims(img11,axis=0)\n",
    "pred = np.argmax(model.predict(img11))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "27af2a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "4\n",
      "mgprob\n"
     ]
    }
   ],
   "source": [
    "img12 = image.load_img(\"C:/Users/svneh/Downloads/cmnmym.png\",target_size=(120,120))\n",
    "img12 = image.img_to_array(img12)\n",
    "img12 = np.expand_dims(img12,axis=0)\n",
    "pred = np.argmax(model.predict(img12))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4c3f72b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "2\n",
      "jglowl\n"
     ]
    }
   ],
   "source": [
    "img13 = image.load_img(\"C:/Users/svneh/Downloads/bonegl.png\",target_size=(120,120))\n",
    "img13 = image.img_to_array(img13)\n",
    "img13 = np.expand_dims(img13,axis=0)\n",
    "pred = np.argmax(model.predict(img13))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a7d7f6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "15\n",
      "blasti\n"
     ]
    }
   ],
   "source": [
    "img14 = image.load_img(\"C:/Users/svneh/Downloads/blasti.png\",target_size=(120,120))\n",
    "img14 = image.img_to_array(img14)\n",
    "img14 = np.expand_dims(img14,axis=0)\n",
    "pred = np.argmax(model.predict(img14))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "eaa2f197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "4\n",
      "mgprob\n"
     ]
    }
   ],
   "source": [
    "img15 = image.load_img(\"C:/Users/svneh/Downloads/brhkyt.png\",target_size=(120,120))\n",
    "img15 = image.img_to_array(img15)\n",
    "img15 = np.expand_dims(img15,axis=0)\n",
    "pred = np.argmax(model.predict(img15))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4775051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hence we can see that it is still not predicting properly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da5db47",
   "metadata": {},
   "source": [
    "# Model Tuning(with Drop out , batch normalisation , early stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3b8a34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6e9ab0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Convolution2D(12,(3,3),activation = 'relu',input_shape=(120,120,3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "    Dropout(0.2),\n",
    "    Convolution2D(24,(3,3),activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "    Dropout(0.2),\n",
    "    Convolution2D(36,(3,3),activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(62,activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    Dense(32,activation = 'relu'),\n",
    "    Dense(16,activation = 'relu'),\n",
    "    Dense(16,activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3e4246d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_22 (Conv2D)          (None, 118, 118, 12)      336       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 118, 118, 12)     48        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 59, 59, 12)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 59, 59, 12)        0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 57, 57, 24)        2616      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 57, 57, 24)       96        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 28, 28, 24)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 28, 28, 24)        0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 26, 26, 36)        7812      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 26, 26, 36)       144       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 13, 13, 36)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 13, 13, 36)        0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 6084)              0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 62)                377270    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 62)               248       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 62)                0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 32)                2016      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 391,386\n",
      "Trainable params: 391,118\n",
      "Non-trainable params: 268\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "388baf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',metrics=['accuracy'],loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "705cf849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c092a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = 'val_accuracy',patience = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "423b1b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 39s 2s/step - loss: 2.9236 - accuracy: 0.0400 - val_loss: 2.7917 - val_accuracy: 0.0382\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 34s 2s/step - loss: 2.6554 - accuracy: 0.1000 - val_loss: 2.8382 - val_accuracy: 0.0573\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 34s 2s/step - loss: 2.5238 - accuracy: 0.2000 - val_loss: 2.9831 - val_accuracy: 0.0573\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 34s 2s/step - loss: 2.4870 - accuracy: 0.2800 - val_loss: 2.9849 - val_accuracy: 0.0573\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 34s 2s/step - loss: 2.3373 - accuracy: 0.2533 - val_loss: 3.3228 - val_accuracy: 0.0573\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 34s 2s/step - loss: 2.1425 - accuracy: 0.3533 - val_loss: 3.2711 - val_accuracy: 0.0573\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 34s 2s/step - loss: 2.1724 - accuracy: 0.4200 - val_loss: 3.2067 - val_accuracy: 0.0573\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 34s 2s/step - loss: 2.0310 - accuracy: 0.4200 - val_loss: 3.1572 - val_accuracy: 0.0573\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 34s 2s/step - loss: 2.0934 - accuracy: 0.3400 - val_loss: 3.4490 - val_accuracy: 0.0764\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 35s 2s/step - loss: 1.8162 - accuracy: 0.4333 - val_loss: 3.3986 - val_accuracy: 0.0510\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 34s 2s/step - loss: 1.8976 - accuracy: 0.4667 - val_loss: 3.0101 - val_accuracy: 0.1401\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 34s 2s/step - loss: 1.5797 - accuracy: 0.5400 - val_loss: 3.2218 - val_accuracy: 0.0701\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 33s 2s/step - loss: 1.5944 - accuracy: 0.5467 - val_loss: 3.4229 - val_accuracy: 0.0573\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 33s 2s/step - loss: 1.5104 - accuracy: 0.5467 - val_loss: 3.2414 - val_accuracy: 0.0764\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 33s 2s/step - loss: 1.5512 - accuracy: 0.5333 - val_loss: 3.6186 - val_accuracy: 0.0573\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 33s 2s/step - loss: 1.5210 - accuracy: 0.5400 - val_loss: 3.5054 - val_accuracy: 0.0701\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 33s 2s/step - loss: 1.3763 - accuracy: 0.6267 - val_loss: 3.6285 - val_accuracy: 0.0637\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 33s 2s/step - loss: 1.4049 - accuracy: 0.5867 - val_loss: 3.7458 - val_accuracy: 0.0637\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 33s 2s/step - loss: 1.3038 - accuracy: 0.5867 - val_loss: 3.6038 - val_accuracy: 0.0955\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(train,epochs =50,\n",
    "                     validation_data = test ,\n",
    "                      batch_size=5,\n",
    "                      callbacks=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "adc46e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 137ms/step\n",
      "8\n",
      "himbul\n"
     ]
    }
   ],
   "source": [
    "img7 = image.load_img(\"C:/Users/svneh/Downloads/indvul.png\",target_size=(120,120))\n",
    "img7 = image.img_to_array(img7)\n",
    "img7 = np.expand_dims(img7,axis=0)\n",
    "pred = np.argmax(model.predict(img7))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ac0f4ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "2\n",
      "jglowl\n"
     ]
    }
   ],
   "source": [
    "img4 = image.load_img(\"C:/Users/svneh/Downloads/hilpig.jpg\",target_size=(120,120))\n",
    "img4 = image.img_to_array(img4)\n",
    "img4 = np.expand_dims(img4,axis=0)\n",
    "pred = np.argmax(model.predict(img4))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4b7955dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "2\n",
      "jglowl\n"
     ]
    }
   ],
   "source": [
    "img5 = image.load_img(\"C:/Users/svneh/Downloads/himbul.jpg\",target_size=(120,120))\n",
    "img5 = image.img_to_array(img5)\n",
    "img5 = np.expand_dims(img5,axis=0)\n",
    "pred = np.argmax(model.predict(img5))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5d96eb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "2\n",
      "jglowl\n"
     ]
    }
   ],
   "source": [
    "img6 = image.load_img(\"C:/Users/svneh/Downloads/hsparo.jpg\",target_size=(120,120))\n",
    "img6 = image.img_to_array(img6)\n",
    "img6 = np.expand_dims(img6,axis=0)\n",
    "pred = np.argmax(model.predict(img6))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9a53ae3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "2\n",
      "jglowl\n"
     ]
    }
   ],
   "source": [
    "img3 = image.load_img(\"C:/Users/svneh/Downloads/rebimg.jpg\",target_size=(120,120))\n",
    "img3 = image.img_to_array(img3)\n",
    "img3 = np.expand_dims(img3,axis=0)\n",
    "pred = np.argmax(model.predict(img3))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0a035d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "2\n",
      "jglowl\n"
     ]
    }
   ],
   "source": [
    "img2 = image.load_img(\"C:/Users/svneh/Downloads/ibicrw.jpg\",target_size=(120,120))\n",
    "img2 = image.img_to_array(img2)\n",
    "img2 = np.expand_dims(img2,axis=0)\n",
    "pred = np.argmax(model.predict(img2))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "474d8991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "2\n",
      "jglowl\n"
     ]
    }
   ],
   "source": [
    "img1 = image.load_img(\"C:/Users/svneh/Downloads/jglowl.jpg\",target_size=(120,120))\n",
    "img1 = image.img_to_array(img1)\n",
    "img1 = np.expand_dims(img1,axis=0)\n",
    "pred = np.argmax(model.predict(img1))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e1b8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0d9ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83b96ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
